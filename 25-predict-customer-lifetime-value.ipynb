{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Customer Lifetime Value Prediction\n",
    "\n",
    "Notes from this notebook comes from various resources listed at the end of the notebook. This will be good exposure to using more plotly to produce interactable plots vs. matplotlib as well as using XGBoost for prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Areas of Focus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Customer Lifetime Value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toolbox 101\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "# import pandas_profiling\n",
    "import numpy as np\n",
    "import random as rand\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# import plotly.plotly as py\n",
    "import plotly.graph_objs as go # graph_objects in version 4 (currently have plotly v3 installed)\n",
    "import plotly.offline as pyoff\n",
    "\n",
    "# Stats\n",
    "from scipy.stats import norm, skew\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "from scipy import stats\n",
    "\n",
    "# Models\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.svm import SVR\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor, plot_importance \n",
    "\n",
    "# Evaluation\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error #RMSE\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Ignore useless warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "# Preset data display\n",
    "pd.options.display.max_seq_items = 5000\n",
    "pd.options.display.max_rows = 5000\n",
    "\n",
    "# Set palette\n",
    "flatui = [\"#9b59b6\", \"#3498db\", \"#95a5a6\", \"#e74c3c\", \"#34495e\", \"#2ecc71\"]\n",
    "sns.set_palette(flatui)\n",
    "sns.palplot(sns.color_palette(flatui))\n",
    "#34495e\n",
    "\n",
    "seed = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pct_bar_labels():\n",
    "    '''\n",
    "    Function used to label the relative frequency on top of each bars\n",
    "    '''\n",
    "    # Set font size\n",
    "    fs=15\n",
    "    \n",
    "    # Set plot label and ticks\n",
    "    plt.ylabel('Relative Frequency (%)', fontsize=fs)\n",
    "    plt.xticks(rotation=0, fontsize=fs)\n",
    "    plt.yticks([])\n",
    "    \n",
    "    # Set individual bar labels in proportional scale\n",
    "    for x in ax1.patches:\n",
    "        ax1.annotate(str(x.get_height()) + '%', \n",
    "        (x.get_x() + x.get_width()/2., x.get_height()), ha='center', va='center', xytext=(0, 7), \n",
    "        textcoords='offset points', fontsize=fs, color='black')\n",
    "\n",
    "def freq_table(var):\n",
    "    '''\n",
    "    Define plot global variables\n",
    "    Create a function that will populate a frequency table (%)\n",
    "    Get counts per feature then get the percentage over the total counts\n",
    "    '''\n",
    "    global ax, ax1\n",
    "    \n",
    "    # Get Values and pct and combine it into a dataframe\n",
    "    count_freq = var.value_counts()\n",
    "    pct_freq = round(var.value_counts(normalize=True)*100, 2)\n",
    "    \n",
    "    # Create a dataframe\n",
    "    df = pd.DataFrame({'Count': count_freq, 'Percentage': pct_freq})\n",
    "    \n",
    "    # Print variable name\n",
    "    print('Frequency of', var.name, ':')\n",
    "    display(df)\n",
    "    \n",
    "    # Create plot\n",
    "    ax1 = pct_freq.plot.bar(title='Percentage of {}'.format(var.name), figsize=(12,8))\n",
    "    ax1.title.set_size(15)\n",
    "    pct_bar_labels()\n",
    "    plt.show()\n",
    "    \n",
    "# Define a null function\n",
    "def get_nulls(df):\n",
    "    \n",
    "    # Get null pct and counts\n",
    "    null_cols = pd.DataFrame(df.isnull().sum().sort_values(ascending=False), columns=['Null Data Count'])\n",
    "    null_cols_pct = pd.DataFrame(round(df.isnull().sum().sort_values(ascending=False)/len(df),5), columns=['Null Data Pct'])\n",
    "\n",
    "    # Combine dataframes horizontally\n",
    "    null_cols_df = pd.DataFrame(pd.concat([null_cols, null_cols_pct], axis=1))\n",
    "\n",
    "    all_nulls = null_cols_df[null_cols_df['Null Data Pct']>0]\n",
    "\n",
    "    # Print\n",
    "    print('There are', len(all_nulls), 'columns with missing values.')\n",
    "    return all_nulls\n",
    "\n",
    "# Define plot_nulls function\n",
    "def plot_nulls(train):\n",
    "    # Get null pct and counts\n",
    "    null_cols = pd.DataFrame(train.isnull().sum().sort_values(ascending=False), columns=['Null Data Count'])\n",
    "    null_cols_pct = pd.DataFrame(round(train.isnull().sum().sort_values(ascending=False)/len(train),5)*100, columns=['Null Data %'])\n",
    "\n",
    "    # Combine horizontally (axis=1) into a dataframe with column names (keys=[]) then to a data frame\n",
    "    null_cols_df = pd.DataFrame(pd.concat([null_cols, null_cols_pct], axis=1))\n",
    "\n",
    "    all_nulls = null_cols_df[null_cols_df['Null Data %']>0]\n",
    "\n",
    "    # Create figure space\n",
    "    if len(all_nulls) > 8:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "    elif len(all_nulls) > 5:\n",
    "        plt.figure(figsize=(6, 8))\n",
    "    else:\n",
    "        plt.figure(figsize=(4, 8))\n",
    "\n",
    "    # Create plot\n",
    "    sns.barplot(x=all_nulls.index,\n",
    "                y='Null Data %',\n",
    "                data=all_nulls)\n",
    "\n",
    "    # Set plot features\n",
    "    plt.ylim(0, 100)\n",
    "    plt.xticks(rotation='90')\n",
    "    plt.xlabel('Features', fontsize=15)\n",
    "    plt.ylabel('Percent of Missing Values', fontsize=15)\n",
    "    plt.title('Percent of Missing Data by Features', fontsize=15)\n",
    "    plt.show()\n",
    "    \n",
    "# Create a new function to capture feature importance for models\n",
    "def feature_importance(model):\n",
    "    \n",
    "    importance = pd.DataFrame({'Feature': headers,\n",
    "                               'Importance': np.round(model.feature_importances_,3)})\n",
    "    \n",
    "    importance = importance.sort_values(by = 'Importance', ascending = False).set_index('Feature')\n",
    "    \n",
    "    return importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "data = pd.read_csv('LargeData/18-online-retail.csv', encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previous data cleaning\n",
    "- Select only UK customers\n",
    "- Change date to datetime\n",
    "- Check data summaries\n",
    "- Remove null customer ID if we group the data to users again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('Country')['Country'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query\n",
    "data = data.query(\"Country=='United Kingdom'\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['InvoiceDate'] = pd.to_datetime(data['InvoiceDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_nulls(data))\n",
    "plot_nulls(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "- \n",
    "- \n",
    "- \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (TensorFlow)",
   "language": "python",
   "name": "tf-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
