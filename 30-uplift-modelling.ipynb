{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Uplift Modelling\n",
    "Notes from this notebook comes from various resources listed at the end of the notebook. This will be good exposure to using more plotly to produce interactable plots vs. matplotlib as well predictive modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Areas of Focus\n",
    "\n",
    "- Uplift modelling\n",
    "    - Used to make campaigns more efficient by:\n",
    "        - Targeting specific segments based on uplift score\n",
    "        - Try different offers based on customer's uplift score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Problem\n",
    "\n",
    "Segmentation helps growth hackers increase conversion and be cost-efficient and maximize return for a given budget/time/effort constraint. \n",
    "\n",
    "What if you're about to launch a promotional campaign and you know which segment you want to target? Do you need to send everyone the offer? We definitely don't. Just like using RFM segmentation, groups vary and each can have a separate action that will be more efficient than another. \n",
    "\n",
    "In the current target group, there will be customers who are going to purchase anyways. Why waste budget on that group? We shouldn't and that's what scoring is about. One way is to identify the segments based on an approach like below:\n",
    "\n",
    "- Treatment responders: customers that will purchase only if they receive an offer\n",
    "\n",
    "- Treatment non-responders: customers that won't purchase in any case\n",
    "\n",
    "- Control responders: customers that will purchase without an offer\n",
    "\n",
    "- Control non-responders: customers that will not purchase if they don't receive an offer\n",
    "\n",
    "With the information above, we can see the differences between the groups. We want to have as much responder type customers (besides responders that will buy with or without an offer). So what we need to do is create strategies revolving around the groups with the highest chance of conversion, which are Treatment Responders (TR) and Control Non-Responders (CN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toolbox 101\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "# import pandas_profiling\n",
    "import numpy as np\n",
    "import random as rand\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# import plotly.plotly as py\n",
    "import plotly.graph_objs as go # graph_objects in version 4 (currently have plotly v3 installed)\n",
    "import plotly.offline as pyoff\n",
    "\n",
    "# Stats\n",
    "from scipy.stats import norm, skew\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "from scipy import stats\n",
    "\n",
    "# Ignore useless warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "# Preset data display\n",
    "pd.options.display.max_seq_items = 5000\n",
    "pd.options.display.max_rows = 5000\n",
    "\n",
    "# Set palette\n",
    "flatui = [\"#9b59b6\", \"#3498db\", \"#95a5a6\", \"#e74c3c\", \"#34495e\", \"#2ecc71\"]\n",
    "sns.set_palette(flatui)\n",
    "sns.palplot(sns.color_palette(flatui))\n",
    "#34495e\n",
    "\n",
    "seed = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pct_bar_labels():\n",
    "    '''\n",
    "    Function used to label the relative frequency on top of each bars\n",
    "    '''\n",
    "    # Set font size\n",
    "    fs=15\n",
    "    \n",
    "    # Set plot label and ticks\n",
    "    plt.ylabel('Relative Frequency (%)', fontsize=fs)\n",
    "    plt.xticks(rotation=0, fontsize=fs)\n",
    "    plt.yticks([])\n",
    "    \n",
    "    # Set individual bar labels in proportional scale\n",
    "    for x in ax1.patches:\n",
    "        ax1.annotate(str(x.get_height()) + '%', \n",
    "        (x.get_x() + x.get_width()/2., x.get_height()), ha='center', va='center', xytext=(0, 7), \n",
    "        textcoords='offset points', fontsize=fs, color='black')\n",
    "\n",
    "def freq_table(var):\n",
    "    '''\n",
    "    Define plot global variables\n",
    "    Create a function that will populate a frequency table (%)\n",
    "    Get counts per feature then get the percentage over the total counts\n",
    "    '''\n",
    "    global ax, ax1\n",
    "    \n",
    "    # Get Values and pct and combine it into a dataframe\n",
    "    count_freq = var.value_counts()\n",
    "    pct_freq = round(var.value_counts(normalize=True)*100, 2)\n",
    "    \n",
    "    # Create a dataframe\n",
    "    df = pd.DataFrame({'Count': count_freq, 'Percentage': pct_freq})\n",
    "    \n",
    "    # Print variable name\n",
    "    print('Frequency of', var.name, ':')\n",
    "    display(df)\n",
    "    \n",
    "    # Create plot\n",
    "    ax1 = pct_freq.plot.bar(title='Percentage of {}'.format(var.name), figsize=(12,8))\n",
    "    ax1.title.set_size(15)\n",
    "    pct_bar_labels()\n",
    "    plt.show()\n",
    "    \n",
    "# Define a null function\n",
    "def get_nulls(df):\n",
    "    \n",
    "    # Get null pct and counts\n",
    "    null_cols = pd.DataFrame(df.isnull().sum().sort_values(ascending=False), columns=['Null Data Count'])\n",
    "    null_cols_pct = pd.DataFrame(round(df.isnull().sum().sort_values(ascending=False)/len(df),2), columns=['Null Data Pct'])\n",
    "\n",
    "    # Combine dataframes horizontally\n",
    "    null_cols_df = pd.DataFrame(pd.concat([null_cols, null_cols_pct], axis=1))\n",
    "\n",
    "    all_nulls = null_cols_df[null_cols_df['Null Data Pct']>0]\n",
    "\n",
    "    # Print\n",
    "    print('There are', len(all_nulls), 'columns with missing values.')\n",
    "    return all_nulls\n",
    "\n",
    "# Define plot_nulls function\n",
    "def plot_nulls(train):\n",
    "    # Get null pct and counts\n",
    "    null_cols = pd.DataFrame(train.isnull().sum().sort_values(ascending=False), columns=['Null Data Count'])\n",
    "    null_cols_pct = pd.DataFrame(round(train.isnull().sum().sort_values(ascending=False)/len(train),2)*100, columns=['Null Data %'])\n",
    "\n",
    "    # Combine horizontally (axis=1) into a dataframe with column names (keys=[]) then to a data frame\n",
    "    null_cols_df = pd.DataFrame(pd.concat([null_cols, null_cols_pct], axis=1))\n",
    "\n",
    "    all_nulls = null_cols_df[null_cols_df['Null Data %']>0]\n",
    "\n",
    "    # Create figure space\n",
    "    if len(all_nulls) > 8:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "    elif len(all_nulls) > 5:\n",
    "        plt.figure(figsize=(6, 8))\n",
    "    else:\n",
    "        plt.figure(figsize=(4, 8))\n",
    "\n",
    "    # Create plot\n",
    "    sns.barplot(x=all_nulls.index,\n",
    "                y='Null Data %',\n",
    "                data=all_nulls)\n",
    "\n",
    "    # Set plot features\n",
    "    plt.ylim(0, 100)\n",
    "    plt.xticks(rotation='90')\n",
    "    plt.xlabel('Features', fontsize=15)\n",
    "    plt.ylabel('Percent of Missing Values', fontsize=15)\n",
    "    plt.title('Percent of Missing Data by Features', fontsize=15)\n",
    "    plt.show()\n",
    "    \n",
    "# Create a new function to capture feature importance for models\n",
    "def feature_importance(model):\n",
    "    \n",
    "    importance = pd.DataFrame({'Feature': headers,\n",
    "                               'Importance': np.round(model.feature_importances_,3)})\n",
    "    \n",
    "    importance = importance.sort_values(by = 'Importance', ascending = False).set_index('Feature')\n",
    "    \n",
    "    return importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (TensorFlow)",
   "language": "python",
   "name": "tf-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
